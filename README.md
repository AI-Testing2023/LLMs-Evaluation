# Large-Language-Models-Evaluation-Survey

## Journal

## Conference

*NeurIPS (Datasets and Benchmarks Track)*<br>
[[HomePage](https://dblp.uni-trier.de/db/conf/nips/neurips2023.html)]

## Business

**Patronus AI**<br>
*人工智能模型评估公司, 美国.*<br>
[[HomePage](https://www.patronus.ai/)]

## Group

**天津大学自然语言处理实验室(tjunlp-lab)**<br>
*熊德意.*<br>
*天津大学.*<br>
[[HomePage](https://tjunlp-lab.github.io/)]
[[HomePage](https://dyxiong.github.io/)]
[[Github](https://github.com/tjunlp-lab)]

## Evaluation System

**OpenCompass （司南）**<br>
*上海人工智能实验室, 2023.*<br>
[[HomePage](https://opencompass.org.cn/home)]
[[Github](https://opencompass.org.cn/home)]

## Review

**A Survey on Evaluation of Large Language Models.**<br>
*Y. Chang, X. Wang, et al.*<br>
ArXiv, 2023.
[[HomePage](https://arxiv.org/pdf/2307.03109.pdf)]
[[Github](https://github.com/MLGroupJLU/LLM-eval-survey)]

## Testing Capability

### General-Oriented Testing (GOT)

### Understanding

**Measuring massive multitask language understanding.**<br>
*D Hendrycks, C Burns, S Basart, A Zou, M Mazeika, D Song, J Steinhardt.*<br>
ICLR, 2021.
[[HomePage](https://arxiv.org/pdf/2009.03300.pdf?trk=public_post_comment-text)]
[[Github](https://github.com/hendrycks/test)]
[[Datasets](https://huggingface.co/datasets/tasksource/mmlu)]

### Industry-Oriented Testing (IOT)

### Finance

**PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance.**<br>
*Q Xie, W Han, X Zhang, Y Lai, M Peng, A Lopez-Lira, J Huang.*<br>
ArXiv, 2023.
[[HomePage](https://arxiv.org/pdf/2306.05443.pdf)]
[[Github](https://github.com/The-FinAI/PIXIU)]
[[Datasets](https://huggingface.co/ChanceFocus)]

### Application-Oriented Testing (AOT)

#### AI Assistants

**GAIA: a benchmark for General AI Assistants.**<br>
*G Mialon, C Fourrier, C Swift, T Wolf, Y LeCun, T Scialom.*<br>
ArXiv, 2023.
[[HomePage](https://arxiv.org/pdf/2311.12983.pdf?trk=public_post_comment-text)]
[[Datasets](https://huggingface.co/datasets/gaia-benchmark/GAIA)]

### Security-Oriented Testing (SOT)

#### Content Security

**JADE: A Linguistics-based Safety Evaluation Platform for Large Language Models.**<br>
*M Zhang, X Pan, M Yang.*<br>
ArXiv, 2023.
[[HomePage](https://arxiv.org/pdf/2311.00286.pdf)]
[[Github](https://github.com/whitzard-ai/jade-db)]

## Testing Datasets

### Data Generation

**DyVal: Graph-informed Dynamic Evaluation of Large Language Models.**<br>
*K Zhu, J Chen, J Wang, NZ Gong, D Yang, X Xie.*<br>
ICLR, 2024.

## Testing Methods

### Result Evaluation

**JADE: A Linguistics-based Safety Evaluation Platform for Large Language Models.**<br>
*M Zhang, X Pan, M Yang.*<br>
ArXiv, 2023.
[[HomePage](https://arxiv.org/pdf/2311.00286.pdf)]
[[Github](https://github.com/whitzard-ai/jade-db)]

## Testing Tools

**OpenCompass （司南）**<br>
*上海人工智能实验室, 2023.*<br>
[[HomePage](https://opencompass.org.cn/home)]
[[Github](https://opencompass.org.cn/home)]
